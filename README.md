# ASSENT: Compare MTEs on Defects4J

This .md explains the repository.

## ASSENT GUI: Design the experiment to find the most consistent MTE with Ground Truth
* ~~~
  python ASSENT-GUI\main.py
  ~~~
   to run the GUI. (If failed, you should install "tkinter" by pip)
* Select the corresponding options on each page, and finally click on 'generate complete design' on the 'agreement indicator' page to obtain the complete experimental setups.


## DATA

* (Branch coverage .ser raw files) https://figshare.com/articles/dataset/Branch_coverage_raw_files_in_Defects4J/24168123
* (Branch coverage .ser raw files) https://figshare.com/articles/dataset/b2_zip/24171789
* (Statement coverage .txt raw files) https://figshare.com/articles/dataset/Statement_coverage_raw_files_in_Defects4J/24166641
* To run the scripts, the extracted folder should be named as "statement" and "branch", and placed in the same directory.

```
.
│  
├─branch
│  └─commons-codec
│  └─...
└─statement
   └─commons-codec
   └─...
```

## Script



Before running it,  you should install and configure Defects4j correctly.


### RQ1-RQ3: Using manual test suites to compare MTEs

* Run the script by 
~~~
python RQ1.py
~~~
* It will compute OP values for all MTEs.

* You can set the running project and version number on line 546, and you can set the output folder on line 548.

* The scripts for RQ2 and RQ3 can be implemented by simply modifying RQ1 

* For example, if you want to run experiment on Chart with version 1, chang line 546 to:
~~~
project=[['Chart',1,1,[]]]
#form:["project name",start version, end version,[skiped versions list]]
~~~

### RQ4: Using automatic test suites to compare MTEs

* Run the script by 
~~~
python compareAutoTest.py'
~~~
* This script automatically calls the 'gen_tests. pl - g evosuite' command to generate a set of test cases for all fixed versions of the project using EvoSuite

* Then it automatically run the generated set of test cases on the buggy version, and the failed test cases will be marked as triggering test cases

* The other steps are consistent with RQ1. The final generated set of test cases and OP result reports will be stored in the specified location.

* You can set the running project and version number on line 253, and you can set the output folder on line 256.

### RQ5: Using statistical indicators to compare MTEs

Run the script by 
~~~
python RQ5.py
~~~
 This script first samples the test case pool (10%, 20%, 30%, 40%, 50%), generates 100 * 5 test case sets, and then calculates its:

* SC: Specify the location of the statement coverage file by modifying the folders on line 413. It will calculate SC based on the coverage matrix in the file. 
* BC: Please place the branch folder in the same directory as the statement. The BC of the test case set is generated by merging the ser file of a single test case.
* MS/SMS/CMS/COS: The kill matrix obtained from the kill maps is used to compute each metric.
* Ground Truth (fault detection): if at least one triggering test case in the suite, it will be labeled as detected.

Change line 414 to set the path of output.

### RQ6: Using PC to compare MTEs

* Run the script by 
~~~
python RQ6.py
~~~
* To compute PC, the kill matrix and the coverage matrix are used.
* Line 414 and line 415 should be changed as RQ5.